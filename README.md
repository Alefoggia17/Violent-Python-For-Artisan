# ACCAFS

This repository shows an example of using ACCA for evaluating the semantic correctness of the code generated by one of the most cutting-edge artificial intelligence models, namely ChatGPT-3.5.

## ACCA and Installation Guide

*ACCA* (Automating the Correctness Assessment of AI-generated Code for Security Contexts) is a fully automated method to evaluate the correctness of AI-generated code for security purposes. The method uses symbolic execution to assess whether the AI-generated code behaves as a reference implementation, demonstrating a very strong correlation with human-based evaluation, which is considered the ground truth for the assessment in the field.
ACCA works on both Windows and Linux OS and it is strongly recommended to set up an *anaconda* virtual environment, for the installation.

### Step 1: Python Setup

Ensure you have Anaconda3 installed, if not install **Python 3.7** from [*Anaconda*](https://www.anaconda.com) with the following steps:
* Install the list of dependencies described [here](https://docs.anaconda.com/anaconda/install/linux/)
* Download the installer [here](https://repo.anaconda.com/archive/). For example, you can use the `wget` command: `wget https://repo.anaconda.com/archive/Anaconda3-2021.05-Linux-x86_64.sh`, then type `chmod +x Anaconda3-2021.05-Linux-x86_64.sh` and run `bash Anaconda3-2021.05-Linux-x86_64.sh` to complete the installation.
* You may need to add *anaconda directory* to the PATH environment variable (e.g., you can add `export PATH="/path_to_anaconda/anaconda3/bin:$PATH"` to the `bashrc` file).

### Step 2: Dependencies Setup

* Create an anaconda Python 3.7 virtual environment using the command ``conda create -n yourenvname python=3.7``.  
* Activate the environment by typing ``source activate yourenvname``.
* Run ``pip install -r requirements.txt --user`` to install the dependencies.

### Step 3: NASM assembler Setup

* To perform the automatic evaluation of syntactic and semantic correctness of the code snippets generated by the NMT models, you need to set up the NASM assembler. To download and install NASM (version 2.15.05), run the following command `./nasm_setup.sh`.

## Prompt Engineering

A fundamental practice in the field of natural language processing (NLP) is *Prompt Engineering*, especially when working with large language models such as GPT-3 or GPT-4.
This practice involves designing and optimizing prompts, which are the initial instructions or sentences that are given to a language model to elicit desired responses or specific behaviors. Changing the prompt can help improve the quality and relevance of the answers generated by the model.

## Experimental process

The goal of the experiment is to use ACCA for evaluating the code generated by ChatGPT-3.5. We will therefore focus only on the inference phase of the model. The *inference phase* of a model refers to the process during which the model applies what it has learned (during the training phase) to perform real tasks based on the given input data. The experimental process consists of various steps.

### ACCA Installation

### Step 1: Dataset

Al seguente link è possibile estrarre un sottoinsieme di coppie intent/snippet che costituirà il dataset di partenza: https://github.com/dessertlab/ESCAPE/tree/main/datasets/shellcode_ia32_extended.
Dopo aver fatto accesso al link, scaricare solo i file `assembly-test.in` e `assembly-test.out`. Il primo contiene tutte le descrizioni in linguaggio naturale. Il secondo contiene tutti i codici in linguaggio Assembly relativi alle descrizioni in linguaggio naturale.

### Step 2: Creazione del prompt

Nell'ambito del Prompt Engineering. è fondamentale creare dei prompt corretti e precisi per ottenere dallo specifico modello altrettante risposte. In tale esperimento, l'obiettivo è chiedere a ChatGPT-3.5 di generare dei codici in linguaggio Assembly, date le descrizioni in linguaggio naturale. Nella costruzione del prompt è necessario specificare la struttura del codice affinchè venga generato nella forma corretta. Infine, è necessario specificare che il codice generato debba essere estratto in maniera semplice.

!ATTENZIONE!

Si ponga attenzione alla struttura degli snippets di codice. Come è possibile osservare dal file `assembly-test.out` precedentemente scaricato, i codici Assembly sono tutti *single-line*. Le istruzioni su più linee, infatti, sono separate tra loro con `\n`.

Nella seguente cartella è presente il prompt sottoposto a ChatGPT per la creazione dei codici Assembly: 

### Step 3: Sottomissione del prompt

Una volta creato, è necessario sottoporre il prompt al modello. Quindi accedere a ChatGPT (https://chatgpt.com/), incollare il prompt e premere invio.

!ATTENZIONE!

Si consiglia di utilizzare un sottoinsieme di campioni (~50-100) da sottoporre al modello affinchè risponda correttamente senza compiere errori. Se si vuole considerare tutto il dataset (590 campioni), allora è possibile inviare le descrizioni in linguaggio naturale con un rate di 50-100 intents alla volta. Ciò eviterà eventuali errori del modello nella generazione del codice.
 *Nota bene* : errori come sovrapposizione dei campioni, generazione errata del codice, lentezza nel caricamento etc possono essere dovuti alla lunghezza del prompt sottoposto e alla quantità di dati da elaborare. Di conseguenza, si consiglia di effettuare il *refresh* della pagina dopo 3 sottomissioni.

### Step 4: Salvare l'ouput

Dato l'input al modello, risulta necessario salvare l'ouput nella stessa forma del file `assembly-test.out`.

### Step 5: Utilizzo di ACCA

Salvato l'ouput completo, adesso è tutto pronto per l'utilizzo di *ACCA*. Accedere alla repository: https://github.com/dessertlab/ACCA/tree/main ed effettuare il clone con il comando `gh repo clone dessertlab/ACCA`). 
This repository contains:
1. The source code for *ACCA* and references file and predictions file to perform the semantic evaluation of AI-generated code and replicate our empirical analysis. The folder also contains a [README.md](https://github.com/dessertlab/ACCA/blob/main/ACCA/README.md) file explaining how to run the code and how to test *ACCA* on a different pair of references and predictions files. (``ACCA`` folder).
2. The files necessary for setting up the working environment, including the NASM assembler (``requirements.txt`` and ``nasm_setup.sh``).
3. The results we obtained by evaluating the code generated by five AI models encompassed in our analysis, i.e., Seq2Seq, CodeBERT, CodeT5+, PLBart and ChatGPT-3.5. The folder contains an XLSX file with the results of our empirical analysis and a [README.md](https://github.com/dessertlab/ACCA/blob/main/Experimental%20Results/README.md) file describing how to interpret the results (``Experimental Results`` folder).

Una volta scaricata la repository localmente, accedere alla cartella ACCA. To correctly perform the evaluation, make sure to follow these steps:

#### Step 0: Ground Truth and Predictions Files Setup

* Put the file containing your ground truth code snippets in the ``Ground Truth and Predictions/Ground Truth`` folder
* Put the file containing your predicted code snippets in the ``Ground Truth and Predictions/Predictions`` folder

#### Step 1: Syntactic Correctness Analysis
	
* To perform the syntactic evaluation, run the command ``python syntactic_analisys.py``. The script opens up a window that lets you select the file to evaluate. 
* The results of the syntactic analysis are both shown and stored in a .csv file in the ``Output/Output_Syntactic_Analysis`` folder. In the ``Filtered Snippets`` folder you can also find the results filtered by warnings, undefined symbol errors and other errors.

#### Step 2: Semantic Correctness Analysis 

* To perform the syntactic evaluation, run the command ``python semantic_analisys.py``. The script opens up a window that lets you select the file to evaluate. Make sure to select the file containing the results of the previous syntactic analysis.
* The results of the semantic analysis are both shown and stored in a .csv file in the ``Output/Output_Semantic_Analysis`` folder.

### Step 6: Risultati
















